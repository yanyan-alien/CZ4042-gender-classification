{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3cc8778",
      "metadata": {
        "id": "b3cc8778"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aecb427b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aecb427b",
        "outputId": "5a8e32c8-3e0c-425b-f042-13534904618b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/adience\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/adience loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-train\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/celeb-a-train loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-val\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/celeb-a-val loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-test\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/celeb-a-test loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r\r/usr/local/lib/python3.10/dist-packages/deeplake/integrations/pytorch/common.py:126: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from dataprocessing import DataLoaderWrapper\n",
        "\n",
        "data=DataLoaderWrapper(batch_size=32, image_size=224)\n",
        "celebA_train,celebA_val,celebA_test=data.initialize_celebA_dataloaders()\n",
        "adience=data.initialize_adience_dataloaders()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c9506eb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "c9506eb7",
        "outputId": "ad2c3d56-bf71-4308-ecd6-68f696af24c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Prepare to collect the predictions\\nall_probabilities = []\\n\\nwith torch.no_grad():\\n    for test_images, age_labels, gender_labels in celebA_val:\\n        out = model(test_images)\\n\\n        # Apply softmax to calculate probabilities\\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\\n\\n        # Collect the probabilities for further processing or analysis\\n        all_probabilities.append(probabilities)\\n\\n#probabilities = torch.nn.functional.softmax(out[0], dim=0)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "'''\n",
        "# Prepare to collect the predictions\n",
        "all_probabilities = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_images, age_labels, gender_labels in celebA_val:\n",
        "        out = model(test_images)\n",
        "\n",
        "        # Apply softmax to calculate probabilities\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "        # Collect the probabilities for further processing or analysis\n",
        "        all_probabilities.append(probabilities)\n",
        "\n",
        "#probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ede96f3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ede96f3e",
        "outputId": "4de86a36-5a3b-4058-9306-93ceb69a68d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (patch_drop): Identity()\n",
              "  (norm_pre): Identity()\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (fc_norm): Identity()\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "num_classes = 2  # 2 classes: male and female\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2abb234",
      "metadata": {
        "id": "d2abb234",
        "outputId": "37c21ab3-f55f-44b9-f204-c2252682d907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IterableOrderedDict([('images', tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-0.5596, -0.5938, -0.5596,  ..., -0.4226, -0.4397, -0.4054],\n",
            "          [-0.5424, -0.5767, -0.5253,  ..., -0.5596, -0.5082, -0.4054],\n",
            "          [-0.5424, -0.5596, -0.5424,  ..., -0.5938, -0.4568, -0.3712],\n",
            "          ...,\n",
            "          [ 0.4508,  0.5364,  0.6049,  ..., -1.3130, -1.1932, -1.1247],\n",
            "          [ 0.4166,  0.5022,  0.5707,  ..., -1.3987, -1.3473, -1.1589],\n",
            "          [ 0.4166,  0.4851,  0.5536,  ..., -1.3815, -1.3130, -1.2274]],\n",
            "\n",
            "         [[-0.3200, -0.3550, -0.3200,  ..., -0.1450, -0.1625, -0.1275],\n",
            "          [-0.3025, -0.3375, -0.2850,  ..., -0.2850, -0.2325, -0.1275],\n",
            "          [-0.3025, -0.3200, -0.3025,  ..., -0.3200, -0.1800, -0.0924],\n",
            "          ...,\n",
            "          [-0.0749, -0.0049,  0.0301,  ..., -1.0203, -0.8803, -0.8277],\n",
            "          [-0.1099, -0.0574, -0.0049,  ..., -1.1078, -1.0553, -0.8803],\n",
            "          [-0.1099, -0.0749, -0.0224,  ..., -1.0903, -1.0203, -0.9503]],\n",
            "\n",
            "         [[ 0.0431,  0.0082,  0.0431,  ...,  0.2348,  0.1825,  0.2173],\n",
            "          [ 0.0605,  0.0256,  0.0779,  ...,  0.0953,  0.1128,  0.2173],\n",
            "          [ 0.0605,  0.0431,  0.0605,  ...,  0.0431,  0.1999,  0.2871],\n",
            "          ...,\n",
            "          [-0.1835, -0.1138, -0.0615,  ..., -0.8981, -0.7587, -0.7064],\n",
            "          [-0.2184, -0.1661, -0.0964,  ..., -0.9678, -0.9330, -0.7587],\n",
            "          [-0.2184, -0.1661, -0.1138,  ..., -0.9330, -0.8981, -0.8284]]]])), ('genders', tensor([[2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [2],\n",
            "        [0],\n",
            "        [2],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [0],\n",
            "        [2],\n",
            "        [0],\n",
            "        [0],\n",
            "        [2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [0]])), ('ages', tensor([[ 7],\n",
            "        [ 7],\n",
            "        [10],\n",
            "        [ 7],\n",
            "        [ 2],\n",
            "        [ 7],\n",
            "        [ 4],\n",
            "        [ 0],\n",
            "        [ 2],\n",
            "        [ 0],\n",
            "        [ 7],\n",
            "        [ 7],\n",
            "        [ 1],\n",
            "        [ 0],\n",
            "        [ 1],\n",
            "        [ 0],\n",
            "        [ 6],\n",
            "        [ 0],\n",
            "        [ 2],\n",
            "        [ 0],\n",
            "        [ 2],\n",
            "        [ 7],\n",
            "        [ 7],\n",
            "        [ 2],\n",
            "        [ 1],\n",
            "        [ 7],\n",
            "        [ 2],\n",
            "        [ 0],\n",
            "        [ 7],\n",
            "        [ 7],\n",
            "        [22],\n",
            "        [ 2]]))])\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "for batch in adience:\n",
        "    print(batch)\n",
        "    break  # Just print the first batch to see what's inside\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98fd8ce",
      "metadata": {
        "id": "b98fd8ce"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in adience:  # Assuming the DataLoader returns a dictionary\n",
        "        images = batch['images'].to(device)\n",
        "\n",
        "        # Make sure genders are in the correct shape and type\n",
        "        genders = batch['genders']\n",
        "        if len(genders.size()) > 1:  # Assuming genders could be one-hot encoded\n",
        "            genders = torch.argmax(genders, dim=1)\n",
        "        genders = genders.to(device).long()  # Ensure the tensor is of type torch.long\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, genders)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == genders).sum().item()\n",
        "        total += genders.size(0)\n",
        "\n",
        "    avg_train_loss = total_loss / len(adience)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_accuracy = correct / total\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "    '''\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    total_val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for batch in adience_val:\n",
        "            val_images = batch['images'].to(device)\n",
        "\n",
        "            # Make sure genders are in the correct shape and type for validation\n",
        "            val_genders = batch['genders']\n",
        "            if len(val_genders.size()) > 1:  # Assuming genders could be one-hot encoded\n",
        "                val_genders = torch.argmax(val_genders, dim=1)\n",
        "            val_genders = val_genders.to(device).long()\n",
        "\n",
        "\n",
        "            # Forward pass\n",
        "            val_outputs = model(val_images)\n",
        "            val_loss = criterion(val_outputs, val_genders)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, val_predicted = torch.max(val_outputs, 1)\n",
        "            val_correct += (val_predicted == val_genders).sum().item()\n",
        "            val_total += val_genders.size(0)\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(adience_val)\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "    '''\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'adience_vit_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:pass"
      ],
      "metadata": {
        "id": "7tLZ3j8WB5sp"
      },
      "id": "7tLZ3j8WB5sp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_accuracies, label='Train')\n",
        "plt.plot(val_accuracies, label='Validation')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(val_losses, label='Validation')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RyJd2XsvVO3B"
      },
      "id": "RyJd2XsvVO3B",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}