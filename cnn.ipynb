{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/adience\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/adience loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/celeb-a-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-val\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/celeb-a-val loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/celeb-a-test loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "from dataprocessing import DataLoaderWrapper\n",
    "\n",
    "data=DataLoaderWrapper(batch_size=32)\n",
    "celebA_train,celebA_val,celebA_test=data.initialize_celebA_dataloaders()\n",
    "adience=data.initialize_adience_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Levi_Hassner(nn.Module):\n",
    "    def __init__(self,output=2,deformable=False) -> None:\n",
    "        super().__init__()\n",
    "        self.deformable=deformable\n",
    "\n",
    "        self.layers=nn.Sequential(OrderedDict([\n",
    "            # first convolutional layer\n",
    "            ('conv1',nn.Conv2d(3, 96, 7, padding='valid', stride=4)),  # No padding\n",
    "            ('relu1',nn.ReLU()),\n",
    "            ('maxpool1',nn.MaxPool2d(3, stride=2)),  # Max pooling over a (3, 3) window with 2 pixel stride)\n",
    "            ('lrn1',nn.LocalResponseNorm(size=5, k=2, alpha=10**(-4), beta=0.75)),\n",
    "\n",
    "            # second convolutional layer\n",
    "            ('conv2',nn.Conv2d(96, 256, 5, padding='same')), # Same padding\n",
    "            ('relu2',nn.ReLU()),\n",
    "            ('maxpool2',nn.MaxPool2d(3, stride=2)),  # Max pooling over a (3, 3) window with 2 pixel stride)\n",
    "            ('lrn2',nn.LocalResponseNorm(size=5, k=2, alpha=10**(-4), beta=0.75)),\n",
    "\n",
    "            # third convolutional layer\n",
    "            ('conv3',nn.Conv2d(256, 384, 3, padding='same')),  # Same padding\n",
    "            ('relu3',nn.ReLU()),\n",
    "            ('maxpool3',nn.MaxPool2d(3, stride=2)),  # Max pooling over a (3, 3) window with 2 pixel stride)\n",
    "            ('flatten',nn.Flatten()),\n",
    "\n",
    "            ('fc1',nn.Linear(384*6*6, 512)), # input 384 * 6 * 6 = 13824, output 512\n",
    "            ('relu4',nn.ReLU()),\n",
    "            ('dropout1',nn.Dropout(0.5)),\n",
    "\n",
    "            ('fc2',nn.Linear(512,512)),\n",
    "            ('relu5',nn.ReLU()),\n",
    "            ('dropout2',nn.Dropout(0.5)),\n",
    "            \n",
    "            ('fc3',nn.Linear(512,output)), # output = number of classes \n",
    "        ]))\n",
    "        self.prob=nn.Softmax(dim=1) # new stuff to check if its causes harm\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.layers(x)\n",
    "        prob=self.prob(x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Levi_Hassner(\n",
       "  (layers): Sequential(\n",
       "    (conv1): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=valid)\n",
       "    (relu1): ReLU()\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "    (relu2): ReLU()\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (relu3): ReLU()\n",
       "    (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
       "    (relu4): ReLU()\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (relu5): ReLU()\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (prob): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_model = Levi_Hassner()\n",
    "gender_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Levi_Hassner(\n",
       "  (layers): Sequential(\n",
       "    (conv1): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=valid)\n",
       "    (relu1): ReLU()\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "    (relu2): ReLU()\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (relu3): ReLU()\n",
       "    (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
       "    (relu4): ReLU()\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (relu5): ReLU()\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (fc3): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       "  (prob): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model = Levi_Hassner(output=8)\n",
    "age_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/deeplake/integrations/pytorch/common.py:126: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/remeliashirlley/Documents/GitHub/CZ4042-gender-classification/cnn.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/remeliashirlley/Documents/GitHub/CZ4042-gender-classification/cnn.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(celebA_train):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/remeliashirlley/Documents/GitHub/CZ4042-gender-classification/cnn.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/remeliashirlley/Documents/GitHub/CZ4042-gender-classification/cnn.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39mmale\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/integrations/pytorch/dataset.py:167\u001b[0m, in \u001b[0;36mTorchDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     schedule\u001b[39m.\u001b[39mshuffle()\n\u001b[1;32m    165\u001b[0m stream \u001b[39m=\u001b[39m streaming\u001b[39m.\u001b[39mread(schedule)\n\u001b[0;32m--> 167\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m stream:\n\u001b[1;32m    168\u001b[0m     \u001b[39myield\u001b[39;00m _process(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/core/io.py:351\u001b[0m, in \u001b[0;36mSampleStreaming.read\u001b[0;34m(self, schedule)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, schedule: Schedule) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m    350\u001b[0m     \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m schedule\u001b[39m.\u001b[39m_blocks:\n\u001b[0;32m--> 351\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream(block)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/core/io.py:396\u001b[0m, in \u001b[0;36mSampleStreaming.stream\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    394\u001b[0m     chunks\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(chunks) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 396\u001b[0m     data \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mread_sample_from_chunk(\n\u001b[1;32m    397\u001b[0m         idx, chunk, decompress\u001b[39m=\u001b[39;49mdecompress, to_pil\u001b[39m=\u001b[39;49mto_pil\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    399\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m decompress:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/core/chunk_engine.py:1843\u001b[0m, in \u001b[0;36mChunkEngine.read_sample_from_chunk\u001b[0;34m(self, global_sample_index, chunk, cast, copy, decompress, to_pil)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(chunk, SampleCompressedChunk)\n\u001b[1;32m   1835\u001b[0m     \u001b[39mreturn\u001b[39;00m chunk\u001b[39m.\u001b[39mread_sample(\n\u001b[1;32m   1836\u001b[0m         local_sample_index,\n\u001b[1;32m   1837\u001b[0m         cast\u001b[39m=\u001b[39mcast,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         to_pil\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1841\u001b[0m     )\n\u001b[0;32m-> 1843\u001b[0m \u001b[39mreturn\u001b[39;00m chunk\u001b[39m.\u001b[39;49mread_sample(\n\u001b[1;32m   1844\u001b[0m     local_sample_index, cast\u001b[39m=\u001b[39;49mcast, copy\u001b[39m=\u001b[39;49mcopy, decompress\u001b[39m=\u001b[39;49mdecompress\n\u001b[1;32m   1845\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/core/chunk/base_chunk.py:632\u001b[0m, in \u001b[0;36mcatch_chunk_read_error.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    631\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    633\u001b[0m     \u001b[39mexcept\u001b[39;00m EmptyTensorError:\n\u001b[1;32m    634\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/core/chunk/sample_compressed_chunk.py:138\u001b[0m, in \u001b[0;36mSampleCompressedChunk.read_sample\u001b[0;34m(self, local_index, cast, copy, sub_index, stream, decompress, is_tile, to_pil)\u001b[0m\n\u001b[1;32m    131\u001b[0m     buffer \u001b[39m=\u001b[39m decompress_bytes(buffer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression)\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m Polygons\u001b[39m.\u001b[39mfrombuffer(\n\u001b[1;32m    133\u001b[0m         \u001b[39mbytes\u001b[39m(buffer),\n\u001b[1;32m    134\u001b[0m         dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensor_meta\u001b[39m.\u001b[39mdtype,\n\u001b[1;32m    135\u001b[0m         ndim\u001b[39m=\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    136\u001b[0m     )\n\u001b[0;32m--> 138\u001b[0m sample \u001b[39m=\u001b[39m decompress_array(\n\u001b[1;32m    139\u001b[0m     buffer,\n\u001b[1;32m    140\u001b[0m     shape,\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    143\u001b[0m     start_idx\u001b[39m=\u001b[39;49mstart,\n\u001b[1;32m    144\u001b[0m     end_idx\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    145\u001b[0m     step\u001b[39m=\u001b[39;49mstep,\n\u001b[1;32m    146\u001b[0m     reverse\u001b[39m=\u001b[39;49mreverse,\n\u001b[1;32m    147\u001b[0m     to_pil\u001b[39m=\u001b[39;49mto_pil,\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m to_pil:\n\u001b[1;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/deeplake/core/compression.py:336\u001b[0m, in \u001b[0;36mdecompress_array\u001b[0;34m(buffer, shape, dtype, compression, start_idx, end_idx, step, reverse, to_pil, path)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m to_pil:\n\u001b[1;32m    335\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n\u001b[0;32m--> 336\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img)\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mreshape(shape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/PIL/Image.py:673\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 673\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m    674\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e, (\u001b[39mMemoryError\u001b[39;00m, \u001b[39mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/PIL/Image.py:732\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m encoder_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m args \u001b[39m==\u001b[39m ():\n\u001b[1;32m    730\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m--> 732\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    734\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    735\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(celebA_train):\n",
    "    print(data['images'].shape)\n",
    "    print(data['male'].shape)\n",
    "    print(data['young'].shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Levi_Hassner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/deeplake/integrations/pytorch/common.py:126: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6783455014228821\n",
      "1.3590947985649109\n",
      "2.036963641643524\n",
      "0.681087851524353\n",
      "1.3592827320098877\n",
      "2.036513566970825\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gender_model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss=0.0\n",
    "    for i,data in enumerate(celebA_train):\n",
    "        inputs, labels = data['images'],data['male']\n",
    "        labels=torch.argmax(labels,dim=1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(running_loss)\n",
    "        if i==2:break\n",
    "        # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        #     running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in gender_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in gender_model.fc3.parameters(): # unfreeze weights of last layer\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gender_model.fc3.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = resnet18(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/5, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
