{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adience Data Fields\n",
    "\n",
    "- images: tensor containing the image\n",
    "- ages: tensor containing ages (label) of a corresponding image\n",
    "- gender: tensor containing the gender of each image\n",
    "- x: part of the bounding box of the face in the original Flickr image\n",
    "- y: part of the bounding box of the face in the original Flickr image\n",
    "- dx: part of the bounding box of the face in the original Flickr image\n",
    "- dy: part of the bounding box of the face in the original Flickr image\n",
    "- tilt_ang: pose of the face in the original Flickr image\n",
    "- fiducial_yaw_angle: pose of the face in the original Flickr image\n",
    "- fiducial_score: score of the landmark detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adience Data Splits\n",
    "\n",
    "- The Adience dataset training set is composed of 19370 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/adience\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/adience loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/deeplake/integrations/pytorch/common.py:126: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(path='hub://activeloop/adience', read_only=True, tensors=['ages', 'dx', 'dy', 'fiducial_score', 'fiducial_yaw_angle', 'genders', 'images', 'tilt_ang', 'x', 'y'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=deeplake.load('hub://activeloop/adience')\n",
    "dataloader = ds.pytorch(num_workers=0, batch_size=4, shuffle=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    im=Image.fromarray(ds.images[i].numpy().astype('uint8'), 'RGB')\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelebA Data Fields\n",
    "\n",
    "- image: tensor containing the 178Ã—218 image.\n",
    "- bbox: tensor containing bounding box of their respective images.\n",
    "- keypoints: tensor to identify 63 various key points from face\n",
    "- clock_shadow: tensor to check cloak shadow.\n",
    "- arched_eyebrows: tensor to check arch eyebrows.\n",
    "- attractive: tensor to check if attractive or not.\n",
    "- bags_under_eyes: tensor to check if bags are under the eyes.\n",
    "- bald: tensor to check if bald or not.\n",
    "- bangs: tensor to check if bangs are there or not.\n",
    "- big_lips: tensor to check if big lips are there or not.\n",
    "- big_nose: tensor to check if big nose is there or not.\n",
    "- black_hair: tensor to check the presence of black hair.\n",
    "- blond_hair: tensor to check if blond hair or not.\n",
    "- blurry: tensor to check if the image is blurred.\n",
    "- brown_hair: tensor to check the presence of brown hair.\n",
    "- bushy_eyebrows: tensor to check the presence of bushy eyebrows.\n",
    "- chubby: tensor to check if chubby or not.\n",
    "- double_chin: tensor to check the presence of double chin.\n",
    "- eyeglasses: tensor checks the presence of eyebrows.\n",
    "- goatee: tensor to check the presence of a goatee in a person.\n",
    "- gray_hair: tensor to check the presence of gray hair.\n",
    "- heavy_makeup: tensor to check the presence of heavy makeup.\n",
    "- high_cheekbones: tensor to check the presence of high cheekbones.\n",
    "- male: tensor to check if the person is male.\n",
    "- mouth_slightly_open: tensor to check if the mouth is open.\n",
    "- mustache: tensor to check the presence of a mustache.\n",
    "- narrow_eyes: tensor to check narrow eyes or not.\n",
    "- no_beard: tensor to check if the beard is present.\n",
    "- oval_face: tensor to check if the face is oval.\n",
    "- pale_skin: tensor to check if the skin is pale.\n",
    "- pointy_nose: tensor to check if the nose is pointy.\n",
    "- receding_hairline: tensor to check if the hairline is receding.\n",
    "- rosy_cheeks: tensor to check if the cheeks are rosy.\n",
    "- sideburns: tensor to check the presence of sideburns.\n",
    "- smiling: tensor to check if the person is smiling.\n",
    "- straight_hair: tensor to check if the hair is straight.\n",
    "- wavy_hair: tensor to check if the hair is wavy.\n",
    "- wearing_earrings: tensor to check the presence of earing.\n",
    "- wearing_hat: tensor to check the presence of the hat.\n",
    "- wearing_lipstick: tensor to check the presence of lipstick.\n",
    "- wearing_necklace: tensor to check the presence of the necklace.\n",
    "- wearing_necktie: tensor to check the presence of necktie.\n",
    "- young: tensor to check if the person is young."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelebA Data Splits\n",
    "\n",
    "- The CelebA dataset training set is composed of 162,770.\n",
    "- The CelebA dataset test set was composed of 19,962.\n",
    "- The CelebA dataset val set was composed of 19,867."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/celeb-a-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-val\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/celeb-a-val loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/celeb-a-test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/celeb-a-test loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "ds_celebA_train = deeplake.load(\"hub://activeloop/celeb-a-train\")\n",
    "ds_celebA_val = deeplake.load(\"hub://activeloop/celeb-a-val\")\n",
    "ds_celebA_test = deeplake.load(\"hub://activeloop/celeb-a-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/deeplake/integrations/pytorch/common.py:126: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = ds_celebA_train.pytorch(num_workers=0, batch_size=4, shuffle=False)\n",
    "val_dataloader = ds_celebA_val.pytorch(num_workers=0, batch_size=4, shuffle=False)\n",
    "test_dataloader = ds_celebA_test.pytorch(num_workers=0, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sat night 4nov\n",
    "discuss on sun 5nov\n",
    "___\n",
    "\n",
    "1. dataprocessing + data augmentation (shirlley)\n",
    "2. network architecture CNN + deformable conv (yanqi)\n",
    "3. network architecture tranformers + visual prompt tuning (tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
